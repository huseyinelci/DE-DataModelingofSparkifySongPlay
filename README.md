<img src="https://github.com/huseyinelci2000/DE-DataModelingofSparkifySongPlay/blob/master/image/RDBS_Sparkify.jpg?raw=true" width="100%">

----
# DE-Data Modeling ETL Processing of Sparkify Song Play
This project is submission for the Nanodegree Data Engineering Program. In this project consists of putting into practice the following titles:
- **Data modeling** with PostgreSQL
- Created database with **star schema**
- Processing **ETL pipeline** on Python

## 1.Introduction
A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analytics team is particularly interested in understanding what songs users are listening to. Currently, they don't have an easy way to query their data, which resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.

They'd like a data engineer to create a Postgres database with tables designed to optimize queries on song play analysis, and bring you on the project. Your role is to create a database schema and ETL pipeline for this analysis. You'll be able to test your database and ETL pipeline by running queries given to you by the analytics team from Sparkify and compare your results with their expected results.

## 2. Project Description
In this project, you will apply what you have learned on data modeling with Postgres and build an ETL pipeline using Python. To complete the project, you will need to define fact and dimension tables for a star schema for a particular analytic focus, and write an ETL pipeline that transfers data from files in two local directories into these tables in Postgres using Python and SQL.

## 3. Datasets and Data Modeling
- Had to implement is a star model for data modeling. Star model is the typical schema for a Data Warehousing. 
- In this project, used datasets from the Sparkify music app logs. These datasets given in JSON files. First of all, should extract into tables.


### 3.1 Song Dataset
The first dataset is a subset of real data from the **Million Song Dataset**. Each file is in **JSON** format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID. For example, here are filepaths to two files in this dataset.

    song_data/A/B/C/TRABCEI128F424C983.json
    song_data/A/A/B/TRAABJL12903CDCF1A.json
And below is an example of what a single song file, **`TRAABJL12903CDCF1A.json`**, looks like.

```json
{
"num_songs": 1, 
"artist_id": "ARJIE2Y1187B994AB7", 
"artist_latitude": null, 
"artist_longitude": null,
"artist_location": "",
"artist_name": "Line Renaud",
"song_id": "SOUPIRU12A6D4FA1E1",
"title": "Der Kleine Dompfaff",
"duration": 152.92036,
"year": 0
}
```

### 3.2 Log Dataset
The second dataset consists of log files in **JSON** format generated by this event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.

The log files in the dataset you'll be working with are partitioned by year and month. For example, here are filepaths to two files in this dataset.

	log_data/2018/11/2018-11-12-events.json
	log_data/2018/11/2018-11-13-events.json
**`2018-11-12-events.json`**, looks like.
```json
{"artist":null, "auth":"Logged In", "firstName":"Walter", "gender":"M",
"itemInSession":0,"lastName":"Frye", "length":null,"level":"free",
"location":"San Francisco-Oakland-Hayward, CA","method":"GET","page":"Home",
"registration":1540919166796.0,"sessionId":38,"song":null,"status":200,"ts":1541105830796,
"userAgent":"\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.143 Safari\/537.36\"","userId":"39"}
...
```

## 4. Files and Project structure
In addition to the data files, this repository has six files:

1. **`data`** folder nested at the home of the project, where all needed jsons reside.
2. **`create_tables.py`** drops and creates tables. You run this file to reset your tables before each time you run your ETL scripts.
3. **`etl.ipynb`** reads and processes a single file from song_data and log_data and loads the data into your tables. This notebook contains detailed instructions on the ETL process for each of the tables.
4. **`etl.py`** reads and processes files from song_data and log_data and loads them into your tables. You can fill this out based on your work in the ETL notebook.
5. **`sql_queries.py`** contains all your sql queries, and is imported into the files bellow.
6. **`test.ipynb`** displays the first few rows of each table to let you check your database.
7. **`README.md`** current file, provides discussion on my project.

With this structured database we can extract several insightful informations from the way our users listens to their musics. Learning from its habits through hidden patterns inside this large quantity of data.

> **Attention**:
You must follow the below bullets for this project. In these bullets, showing how to create this database and then how this database was structured.

**WHAT should to do?**

1. First of all, you must do file of **`sql_queries.py`**.  Wrote DROP, CREATE and INSERT query statements in this file. 
2. After that you should run this code in console or use **`First.ipynb`**:
```python
# 1
!python create_tables.py
```

2. Used **`test.ipynb`** Jupyter Notebook to interactively verify that all tables were created correctly.
3. Now, you should do file of **`etl.ipynb`**

```python
# 3
!python etl.py
```

4. After that, you have to done file of **`etl.py`** 
5. May used **`test.ipynb`** again for verify that all tables were created correctly.
You should do with the **PostgreSQL** database on **Python**. You find these structures in **`First.ipynb`**

## Database Schema
We mentioned above that we will use the Star Schema in this project:
There is one main **`fact table`** containing all the measures associated with each event (What song's each user listening ?) and 4 **`dimentional tables`**, each with a primary key that is being referenced from the fact table. [Click on it about fact table and dimentional tables](https://www.geeksforgeeks.org/difference-between-fact-table-and-dimension-table/)

Why use an [RDMS-relational database](https://db-engines.com/en/article/Relational+DBMS?ref=RDBMS) for this case:
- The amount of our dataset is not big enough to require related solutions for big data.
- This kind of analysis, potential to use PostgreSQL that is more than enough.
- Also, our dataset's types are structured.
- Data needed to answer business questions can be modeled using simple [ERD models](https://www.lucidchart.com/pages/er-diagrams#:~:text=Also%20known%20as%20ERDs%20or,nouns%20and%20relationships%20as%20verbs.)
- We need to use [JOINS](https://www.tutorialspoint.com/postgresql/postgresql_using_joins.htm) for this scenario
<img src="https://github.com/huseyinelci2000/DE-DataModelingofSparkifySongPlay/blob/master/image/RDBS_diagram.png?raw=true" width="80%">

#### Fact Table
**songplays** - records in log data associated with song plays i.e. records with page NextSong
- songplay_id (INT) PRIMARY KEY: ID of each user song play 
- start_time (TIMESTAMP) NOT NULL: Timestamp of beggining of user activity
- user_id (INT) NOT NULL: ID of user
- level (TEXT): User level {free | paid}
- song_id (TEXT) NOT NULL: ID of Song played
- artist_id (TEXT) NOT NULL: ID of Artist of the song played
- session_id (INT): ID of the user Session 
- location (TEXT): User location 
- user_agent (TEXT): Agent used by user to access Sparkify platform

#### Dimension Tables
**users** - users in the app
- user_id (INT) PRIMARY KEY: ID of user
- first_name (TEXT) NOT NULL: Name of user
- last_name (TEXT) NOT NULL: Last Name of user
- gender (TEXT): Gender of user {M | F}
- level (TEXT): User level {free | paid}

**songs** - songs in music database
- song_id (TEXT) PRIMARY KEY: ID of Song
- title (TEXT) NOT NULL: Title of Song
- artist_id (TEXT) NOT NULL: ID of song Artist
- year (INT): Year of song release
- duration (FLOAT) NOT NULL: Song duration in milliseconds

**artists** - artists in music database
- artist_id (TEXT) PRIMARY KEY: ID of Artist
- name (TEXT) NOT NULL: Name of Artist
- location (TEXT): Name of Artist city
- lattitude (FLOAT): Lattitude location of artist
- longitude (FLOAT): Longitude location of artist

**time** - timestamps of records in songplays broken down into specific units
- start_time (TIMESTAMP) PRIMARY KEY: Timestamp of row
- hour (INT): Hour associated to start_time
- day (INT): Day associated to start_time
- week (INT): Week of year associated to start_time
- month (INT): Month associated to start_time 
- year (INT): Year associated to start_time
- weekday (TEXT): Name of week day associated to start_time

<a id="6"></a>
## Source, Licensing, Authors, and Acknowledgements

#### Source
The Source owner is [Million Song Dataset](http://millionsongdataset.com/)
#### Licensing
The data In this project is **OpenSource** and owner is  [Million Song Dataset](http://millionsongdataset.com/). Also, if _you plan to use this database in your article research or else_ you must taken and read main Source in the **Million Song Dataset repository**.
#### Authors
Huseyin ELCI
  |  [Github](https://github.com/huseyinelci2000)  |  [Kaggle](https://www.kaggle.com/huseyinelci)  |  [Linkedin](https://www.linkedin.com/in/huseyinelci/)   |  
#### Acknowledgements
Thanks to  [Million Song Dataset](http://millionsongdataset.com/) for providing cool data with which we can create a cutting edge project.
